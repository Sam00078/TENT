{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TT_experiments_weights.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7PaY6KZmbfBP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yy3gc13nHMR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6NYTcAvln4J"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "**Requires dataset_tensor.npy file in \"Colab Notebooks/Tensorized Transformers/Data\" folder!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaNZqkhqfjiJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/Tensorized Transformers/'\n",
        "DATA_PATH = PATH + 'Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxUZWqils8I"
      },
      "source": [
        "### Clone Tensorized Transformers github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKol2g8WU1d"
      },
      "source": [
        "print('Github username:')\n",
        "git_username = %sx read -p ''\n",
        "git_username = git_username[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkU2f9HhZQB9"
      },
      "source": [
        "print('Github access token (https://github.com/settings/tokens):')\n",
        "git_token = %sx read -p ''\n",
        "git_token = git_token[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6Ej0xOjzbu"
      },
      "source": [
        "# Clone the entire repo.\n",
        "%cd /content\n",
        "!git clone -l -s https://$git_username:$git_token@github.com/onurbil/tensorized_transformers.git tensorized_transformers\n",
        "%cd tensorized_transformers\n",
        "!ls\n",
        "%cd ..\n",
        "\n",
        "REPO_PATH = '/content/tensorized_transformers'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmfy2j6FkjLo"
      },
      "source": [
        "import sys\n",
        "sys.path.append(REPO_PATH)\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9e5tQalzjp"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUxsxY5wlBzO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import model.tt_mod_weights as tt\n",
        "import dataset_tools.split\n",
        "from visualization_tools.visualization import visualize_pos_encoding, attention_plotter\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/notebooks/output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFJ-r1LJaj_a"
      },
      "source": [
        "dir = '/notebooks/output/'  + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Load dataset:\n",
        "filename = DATA_PATH + 'dataset_tensor.npy'\n",
        "# file_path = os.path.join(common.paths.PROCESSED_DATASET_DIR, filename)\n",
        "dataset = np.load(filename, allow_pickle=True)\n",
        "\n",
        "print(dataset.shape)\n",
        "\n",
        "input_length = 4\n",
        "lag = 4\n",
        "train, test = dataset_tools.split.split_train_test(dataset)\n",
        "x_train, y_train = dataset_tools.split.get_xy(train, input_length=input_length, lag=lag)\n",
        "x_test, y_test = dataset_tools.split.get_xy(test, input_length=input_length, lag=lag)\n",
        "\n",
        "#x_train = x_train.astype('float32')\n",
        "x_train = tf.reshape(x_train, (x_train.shape[0], x_train.shape[1], dataset.shape[1], dataset.shape[2]))\n",
        "y_train = tf.reshape(y_train, (y_train.shape[0], dataset.shape[1], dataset.shape[2]))\n",
        "x_test = tf.reshape(x_test, (x_test.shape[0], x_test.shape[1], dataset.shape[1], dataset.shape[2]))\n",
        "y_test = tf.reshape(y_test, (y_test.shape[0], dataset.shape[1], dataset.shape[2]))\n",
        "\n",
        "# x_train = tf.transpose(x_train, perm=(0, 1, 3, 2))\n",
        "# y_train = tf.transpose(y_train, perm=(0, 2, 1))\n",
        "# x_test = tf.transpose(x_test, perm=(0, 1, 3, 2))\n",
        "# y_test = tf.transpose(y_test, perm=(0, 2, 1))\n",
        "\n",
        "print(f'x_train.shape: {x_train.shape}')\n",
        "print(f'x_test.shape: {x_test.shape}')\n",
        "\n",
        "# Parameters:\n",
        "epoch = 300\n",
        "learning_rate = 0.001\n",
        "head_num = 1\n",
        "d_model = head_num * 36\n",
        "dense_units = 64\n",
        "batch_size = 64\n",
        "input_shape = (input_length, x_train.shape[-2], x_train.shape[-1])\n",
        "output_shape = (1, 1)\n",
        "# y_train = y_train[..., 4, 0]\n",
        "# y_test = y_test[..., 4, 0]\n",
        "y_train = y_train[..., 0, 4]\n",
        "y_test = y_test[..., 0, 4]\n",
        "initializer = 'RandomNormal'\n",
        "\n",
        "model = kr.Sequential([\n",
        "    kr.Input(shape=input_shape),\n",
        "    tt.PositionalEncoding(broadcast=True),\n",
        "    tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer),\n",
        "    tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer),\n",
        "    tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer),\n",
        "    tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer),\n",
        "    kr.layers.Flatten(),\n",
        "    kr.layers.Dense(tf.reduce_prod(output_shape), activation='linear'),\n",
        "    kr.layers.Reshape(output_shape),\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer=kr.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])\n",
        "\n",
        "num_examples = 10000\n",
        "x_train = x_train[:num_examples]\n",
        "y_train = y_train[:num_examples]\n",
        "\n",
        "num_test_examples = 200\n",
        "x_test = x_test[:num_test_examples, ...]\n",
        "y_test = y_test[:num_test_examples]\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=epoch, \n",
        "          batch_size=batch_size, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[TensorBoard(log_dir=dir)]\n",
        "          )\n",
        "\n",
        "# print(model.layers[1].attention_weights)\n",
        "labels = np.arange(model.layers[1].attention_weights.shape[1]).tolist()\n",
        "# print(tf.shape(model.layers[1].attention_weights))\n",
        "from visualization_tools.visualization import visualize_pos_encoding, attention_plotter\n",
        "attention_plotter(model.layers[1].attention_weights[5], labels)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "preds = []\n",
        "for i in range(x_test.shape[0]):\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f'prediction: {i + 1}/{x_test.shape[0]}')\n",
        "    preds.append(model.predict(x_test[i][np.newaxis, ...]))\n",
        "pred = np.concatenate(preds, axis=0)\n",
        "mse = np.mean(kr.metrics.mse(y_test, pred))\n",
        "mae = np.mean(kr.metrics.mae(y_test, pred))\n",
        "print(f'mse: {mse}, mae: {mae}')\n",
        "\n",
        "\n",
        "\n",
        "print(pred.flatten().shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "plt.plot(range(pred.size), pred.flatten(), label='pred')\n",
        "plt.plot(range(len(y_test)), y_test, label='true')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PaY6KZmbfBP"
      },
      "source": [
        "#### Old experiments"
      ]
    }
  ]
}