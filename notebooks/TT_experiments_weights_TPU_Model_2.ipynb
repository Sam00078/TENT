{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yy3gc13nHMR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "! pip install -q pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6NYTcAvln4J"
   },
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "**Requires dataset_tensor.npy file in \"Colab Notebooks/Tensorized Transformers/Data\" folder!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaNZqkhqfjiJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PATH = '/content/drive/My Drive/Colab Notebooks/Tensorized Transformers/'\n",
    "DATA_PATH = PATH + 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHxUZWqils8I"
   },
   "source": [
    "### Clone Tensorized Transformers github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmKol2g8WU1d"
   },
   "outputs": [],
   "source": [
    "print('Github username:')\n",
    "git_username = %sx read -p ''\n",
    "git_username = git_username[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkU2f9HhZQB9"
   },
   "outputs": [],
   "source": [
    "print('Github access token (https://github.com/settings/tokens):')\n",
    "git_token =  %sx read -p ''\n",
    "git_token = git_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA6Ej0xOjzbu"
   },
   "outputs": [],
   "source": [
    "# Clone the entire repo.\n",
    "%cd /content\n",
    "!git clone -l -s https://$git_username:$git_token@github.com/onurbil/tensorized_transformers.git tensorized_transformers\n",
    "%cd tensorized_transformers\n",
    "!ls\n",
    "%cd ..\n",
    "\n",
    "REPO_PATH = '/content/tensorized_transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmfy2j6FkjLo"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(REPO_PATH)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl9e5tQalzjp"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUxsxY5wlBzO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model.tt_mode_weights_TPU as tt\n",
    "import dataset_tools.split\n",
    "from visualization_tools.visualization import visualize_pos_encoding, attention_plotter\n",
    "\n",
    "import datetime\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir '/content/drive/My Drive/Colab Notebooks/Tensorized Transformers/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O8WyQhzZO2_"
   },
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "strategy = tf.distribute.TPUStrategy(tpu)#tf.distribute.experimental.TPUStrategy(tpu)\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFJ-r1LJaj_a"
   },
   "outputs": [],
   "source": [
    "dir = './output/'  + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Load dataset:\n",
    "filename = DATA_PATH + 'dataset_tensor.npy'\n",
    "# file_path = os.path.join(common.paths.PROCESSED_DATASET_DIR, filename)\n",
    "dataset = np.load(filename, allow_pickle=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "###### ALL PARAMETERS HERE######:\n",
    "softmax_type = 3\n",
    "input_length = 24\n",
    "lag = 4 # 8 16\n",
    "epoch = 800\n",
    "\n",
    "warmup_steps = 50\n",
    "factor1=-0.6\n",
    "factor2=-1.5\n",
    "\n",
    "learning_rate = 0.0001\n",
    "head_num = 32\n",
    "d_model = 256\n",
    "dense_units = 512\n",
    "batch_size = 4\n",
    "\n",
    "num_examples = 35000 \n",
    "num_valid_examples = 36325 - num_examples\n",
    "initializer = 'RandomNormal'\n",
    "patience = 20\n",
    "\n",
    "num_examples = (num_examples // batch_size) * batch_size\n",
    "num_valid_examples = (num_valid_examples // batch_size) * batch_size\n",
    "\n",
    "train, test = dataset_tools.split.split_train_test(dataset)\n",
    "x_train, y_train = dataset_tools.split.get_xy(train, input_length=input_length, lag=lag)\n",
    "x_test, y_test = dataset_tools.split.get_xy(test, input_length=input_length, lag=lag)\n",
    "\n",
    "#x_train = x_train.astype('float32')\n",
    "x_train = tf.reshape(x_train, (x_train.shape[0], x_train.shape[1], dataset.shape[1], dataset.shape[2]))\n",
    "y_train = tf.reshape(y_train, (y_train.shape[0], dataset.shape[1], dataset.shape[2]))\n",
    "x_test = tf.reshape(x_test, (x_test.shape[0], x_test.shape[1], dataset.shape[1], dataset.shape[2]))\n",
    "y_test = tf.reshape(y_test, (y_test.shape[0], dataset.shape[1], dataset.shape[2]))\n",
    "\n",
    "# Choosing first 29 cities\n",
    "x_train = x_train[:, :, :29, :]\n",
    "y_train = y_train[:, :29, :]\n",
    "x_test = x_test[:, :, :29, :]\n",
    "y_test = y_test[:, :29, :]\n",
    "\n",
    "print(f'FULL_x_train.shape: {x_train.shape}')\n",
    "\n",
    "input_shape = (input_length, x_train.shape[-2], x_train.shape[-1])\n",
    "output_shape = (1, 1)\n",
    "\n",
    "# Choosing temperature as output\n",
    "y_train = y_train[..., 0, 4]\n",
    "y_test = y_test[..., 0, 4]\n",
    "\n",
    "learning_rate = tt.CustomSchedule(d_model, warmup_steps=warmup_steps, factor1=factor1, factor2=factor2) #tt.CustomSchedule(d_model)                 # , warmup_steps=50, factor1=-0.84, factor2=-1.7)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, \n",
    "                                     beta_1=0.9, \n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9\n",
    "                                     )\n",
    "lr_metric = tt.get_lr_metric(optimizer)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adadelta(learning_rate)\n",
    "# optimizer = tf.keras.optimizers.Nadam(learning_rate)\n",
    "\n",
    "temp_learning_rate_schedule = tt.CustomSchedule(d_model, warmup_steps=warmup_steps, factor1=factor1, factor2=factor2)\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(20000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##tf.keras.optimizers.Adadelta\n",
    "\n",
    "with strategy.scope():\n",
    "  model = kr.Sequential([\n",
    "              kr.Input(shape=input_shape),\n",
    "              tt.PositionalEncoding(broadcast=True),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              kr.layers.Flatten(),\n",
    "              kr.layers.Dense(tf.reduce_prod(output_shape), activation='linear'),\n",
    "              kr.layers.Reshape(output_shape),\n",
    "              ])\n",
    "  model.compile(optimizer=optimizer, loss='mae', metrics=['mse', lr_metric])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "x_valid = x_train[- num_valid_examples:, ...]\n",
    "y_valid = y_train[- num_valid_examples:]\n",
    "print(f'x_valid.shape: {x_valid.shape}')\n",
    "\n",
    "x_train = x_train[-num_examples - num_valid_examples:-num_valid_examples, ...]\n",
    "y_train = y_train[-num_examples - num_valid_examples:-num_valid_examples]\n",
    "\n",
    "# x_valid = x_train[-num_examples - num_valid_examples:-num_examples, ...]\n",
    "# y_valid = y_train[-num_examples - num_valid_examples:-num_examples]\n",
    "# print(f'x_valid.shape: {x_valid.shape}')\n",
    "\n",
    "# x_train = x_train[-num_examples:]\n",
    "# y_train = y_train[-num_examples:]\n",
    "\n",
    "print(f'x_train.shape: {x_train.shape}')\n",
    "print(f'x_test.shape: {x_test.shape}')\n",
    "\n",
    "# Callbacks\n",
    "print_attention_weights = kr.callbacks.LambdaCallback(\n",
    "    on_train_end=lambda batch: print(model.layers[1].attention_weights))\n",
    "early_stopping = kr.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=patience,\n",
    "                                            restore_best_weights=True,\n",
    "                                            verbose = 1)\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epoch,\n",
    "    batch_size=batch_size * 8,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[early_stopping]\n",
    "         )\n",
    "#TensorBoard(log_dir=dir), \n",
    "# labels = np.arange(model.layers[1].attention_weights.shape[-2]).tolist()\n",
    "\n",
    "# if (softmax_type == 1 or softmax_type == 2):\n",
    "#     attention_plotter(tf.reshape(model.layers[1].attention_weights[1][0], (input_length,-1)), labels)\n",
    "#     attention_plotter(tf.reshape(model.layers[1].attention_weights[2][0], (input_length,-1)), labels)\n",
    "#     attention_plotter(tf.reshape(model.layers[1].attention_weights[3][0], (input_length,-1)), labels)        \n",
    "#     attention_plotter(tf.reshape(model.layers[1].attention_weights[4][0], (input_length,-1)), labels)        \n",
    "\n",
    "# elif softmax_type == 3:\n",
    "#     # print(model.layers[1].attention_weights[0][3].numpy())\n",
    "#     attention_3d_plotter(model.layers[1].attention_weights[0][3].numpy(), city_labels)\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "pred = model.predict(x_valid)\n",
    "mae = kr.metrics.mae(y_valid.numpy().flatten(), pred.flatten())\n",
    "print(f'Figure mae: {np.mean(mae)}')\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(range(pred.size), pred.flatten(), label='pred')\n",
    "plt.plot(range(len(y_valid)), y_valid, label='true')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n######################## Model description ################################\")\n",
    "model.summary()\n",
    "print(\"softmax_type = \", softmax_type)\n",
    "print(\"Input_length = \", input_length)\n",
    "print(\"Lag = \", lag)\n",
    "print(\"Epoch = \", epoch)\n",
    "print(\"warmup_steps = \", warmup_steps)\n",
    "print(\"factor1 = \", factor1)\n",
    "print(\"factor2 = \", factor2)\n",
    "\n",
    "print(\"LR = \", learning_rate)\n",
    "print(\"Head_num = \", head_num)\n",
    "print(\"d_model = \", d_model)\n",
    "print(\"dense_units = \", dense_units)\n",
    "print(\"batch_size = \", batch_size)\n",
    "\n",
    "print(\"num_examples = \", num_examples)\n",
    "print(\"num_valid_examples = \", num_valid_examples)\n",
    "print(\"input_shape = \", input_shape)\n",
    "print(\"patience = \", patience)\n",
    "\n",
    "pred = model.predict(x_test[-(8813//batch_size)*batch_size:-800, ...])\n",
    "mae = kr.metrics.mae(y_test[-(8813//batch_size)*batch_size:-800, ...].numpy().flatten(), pred.flatten())\n",
    "print(\"\\n\\n######################## Results ##########################################\")\n",
    "print(f'test mae: {np.mean(mae)}')\n",
    "\n",
    "### Saving Model:\n",
    "dir = '/content/drive/My Drive/Colab Notebooks/Model/Entire_Model/tpu_model_lag' + str(lag)\n",
    "localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "model.save(dir, options=localhost_save_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp1c-4vHkcyt"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **TRANSFORM MODEL IN NON TPU MODEL (ALSO SAVING WEIGHTS)** \n",
    "\n",
    "## **-- Need to repeat the model --**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xt0MK3uBSFbO"
   },
   "outputs": [],
   "source": [
    "dir = '/content/drive/My Drive/Colab Notebooks/Model/Weights/tpu_model_lag'+ str(lag) + '.h5'\n",
    "model.save_weights(dir, overwrite=True)\n",
    "\n",
    "inferencing_model =  kr.Sequential([\n",
    "              kr.Input(shape=input_shape),\n",
    "              tt.PositionalEncoding(broadcast=True),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              # tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              # tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              # tt.EncoderLayer(input_length, d_model, head_num, dense_units, initializer, softmax_type, batch_size),\n",
    "              kr.layers.Flatten(),\n",
    "              kr.layers.Dense(tf.reduce_prod(output_shape), activation='linear'),\n",
    "              kr.layers.Reshape(output_shape),\n",
    "              ])\n",
    "inferencing_model.load_weights(dir)\n",
    "inferencing_model.summary()\n",
    "\n",
    "pred = inferencing_model.predict(x_test)\n",
    "mae = kr.metrics.mae(y_test.numpy().flatten(), pred.flatten())\n",
    "print(\"\\n\\n######################## Results ##########################################\")\n",
    "print(f'test mae: {np.mean(mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvPJTRmXlB0l"
   },
   "source": [
    "## **Save entire model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIRsom6VT2Az"
   },
   "outputs": [],
   "source": [
    "dir = '/content/drive/My Drive/Colab Notebooks/Model/Entire_Model/tpu_model_lag' + str(lag)\n",
    "\n",
    "localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "model.save(dir, options=localhost_save_option)\n",
    "\n",
    "# # Restore the weights\n",
    "model2 = tf.keras.models.load_model(dir, options=localhost_save_option, custom_objects={\n",
    "    'lr': tt.get_lr_metric, \n",
    "    'CustomSchedule':tt.CustomSchedule\n",
    "})\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "mae = kr.metrics.mae(y_test.numpy().flatten(), pred.flatten())\n",
    "print(\"\\n\\n######################## Results ##########################################\")\n",
    "print(f'test mae: {np.mean(mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFIypn_H1Bzu"
   },
   "source": [
    "## **Test of the learning rate curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IAKcWNmkTNC"
   },
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "warmup_steps = 50\n",
    "factor1=-0.6\n",
    "factor2=-1.5\n",
    "\n",
    "temp_learning_rate_schedule = tt.CustomSchedule(d_model, warmup_steps=warmup_steps, factor1=factor1, factor2=factor2)\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(10000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TT_experiments_weights_TPU_Model_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
