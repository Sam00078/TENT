{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_load.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yy3gc13nHMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06206442-3e40-4c04-d95d-e828d61c9a7d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "! pip install -q pyyaml h5py  # Required to save models in HDF5 format\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/Tensorized Transformers/'\n",
        "DATA_PATH = PATH + 'Data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxUZWqils8I"
      },
      "source": [
        "### Clone Tensorized Transformers github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKol2g8WU1d"
      },
      "source": [
        "print('Github username:')\n",
        "git_username = %sx read -p ''\n",
        "git_username = git_username[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkU2f9HhZQB9"
      },
      "source": [
        "print('Github access token (https://github.com/settings/tokens):')\n",
        "git_token =  %sx read -p ''\n",
        "git_token = git_token[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6Ej0xOjzbu"
      },
      "source": [
        "# Clone the entire repo.\n",
        "%cd /content\n",
        "!git clone -l -s https://$git_username:$git_token@github.com/onurbil/tensorized_transformers.git tensorized_transformers\n",
        "%cd tensorized_transformers\n",
        "!ls\n",
        "%cd ..\n",
        "\n",
        "REPO_PATH = '/content/tensorized_transformers'\n",
        "\n",
        "import sys\n",
        "sys.path.append(REPO_PATH)\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9e5tQalzjp"
      },
      "source": [
        "## Model restore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUxsxY5wlBzO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import model.tt_mode_weights_TPU as tt\n",
        "import dataset_tools.split\n",
        "from visualization_tools.visualization import visualize_pos_encoding, attention_plotter, attention_3d_plotter, loop_plotter\n",
        "from common.variables import city_labels\n",
        "\n",
        "import datetime\n",
        "\n",
        "from dataset_tools.denormalization import denormalize_feature\n",
        "import copy\n",
        "\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(tpu)#tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "### Data load\n",
        "dir = './output/'  + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Load dataset:\n",
        "filename = DATA_PATH + 'dataset_tensor.npy'\n",
        "# file_path = os.path.join(common.paths.PROCESSED_DATASET_DIR, filename)\n",
        "dataset = np.load(filename, allow_pickle=True)\n",
        "\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIRsom6VT2Az"
      },
      "source": [
        "### Parameters of the model to be restored \r\n",
        "feature = 4  ### 4 for temperature, 7 for wind speed\r\n",
        "lag = 4\r\n",
        "dirModel = '/content/drive/My Drive/Colab Notebooks/Model/SavedModels/lag_' + str(lag) + '_feature_' + str(feature)\r\n",
        "\r\n",
        "###### ALL PARAMETERS HERE######:\r\n",
        "input_length = 16\r\n",
        "num_examples = 35000 \r\n",
        "num_valid_examples = 36325 - num_examples\r\n",
        "batch_size = 4\r\n",
        "\r\n",
        "\r\n",
        "num_examples = (num_examples // (batch_size*8)) * (batch_size*8)\r\n",
        "num_valid_examples = (num_valid_examples // (batch_size*8)) * (batch_size*8)\r\n",
        "\r\n",
        "train, test = dataset_tools.split.split_train_test(dataset)\r\n",
        "x_train, y_train = dataset_tools.split.get_xy(train, input_length=input_length, lag=lag)\r\n",
        "x_test, y_test = dataset_tools.split.get_xy(test, input_length=input_length, lag=lag)\r\n",
        "\r\n",
        "#x_train = x_train.astype('float32')\r\n",
        "x_train = tf.reshape(x_train, (x_train.shape[0], x_train.shape[1], dataset.shape[1], dataset.shape[2]))\r\n",
        "y_train = tf.reshape(y_train, (y_train.shape[0], dataset.shape[1], dataset.shape[2]))\r\n",
        "x_test = tf.reshape(x_test, (x_test.shape[0], x_test.shape[1], dataset.shape[1], dataset.shape[2]))\r\n",
        "y_test = tf.reshape(y_test, (y_test.shape[0], dataset.shape[1], dataset.shape[2]))\r\n",
        "\r\n",
        "# Choosing first 29 cities\r\n",
        "x_train = x_train[:, :, :29, :]\r\n",
        "y_train = y_train[:, :29, :]\r\n",
        "x_test = x_test[:, :, :29, :]\r\n",
        "y_test = y_test[:, :29, :]\r\n",
        "\r\n",
        "\r\n",
        "# Choosing temperature as output\r\n",
        "y_train = y_train[..., 0, feature]\r\n",
        "y_test = y_test[..., 0, feature]\r\n",
        "\r\n",
        "x_valid = x_train[- num_valid_examples:, ...]\r\n",
        "y_valid = y_train[- num_valid_examples:]\r\n",
        "print(f'x_valid.shape: {x_valid.shape}')\r\n",
        "\r\n",
        "x_train = x_train[-num_examples - num_valid_examples:-num_valid_examples, ...]\r\n",
        "y_train = y_train[-num_examples - num_valid_examples:-num_valid_examples]\r\n",
        "\r\n",
        "print(f'x_train.shape: {x_train.shape}')\r\n",
        "print(f'x_test.shape: {x_test.shape}')\r\n",
        "\r\n",
        "# # Restore the model\r\n",
        "localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\r\n",
        "model = tf.keras.models.load_model(dirModel, options=localhost_save_option, custom_objects={\r\n",
        "    'lr': tt.get_lr_metric, \r\n",
        "    'CustomSchedule':tt.CustomSchedule\r\n",
        "})\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "Xtest = copy.deepcopy(x_test[-(8813//(batch_size*8))*(batch_size*8):-796, ...])\r\n",
        "Ytest = copy.deepcopy(y_test[-(8813//(batch_size*8))*(batch_size*8):-796, ...])\r\n",
        "pred = model.predict(Xtest)\r\n",
        "\r\n",
        "predictions = denormalize_feature(pred, feature)\r\n",
        "real = denormalize_feature(Ytest, feature).numpy()   #real[-size:, ...]\r\n",
        "\r\n",
        "mae = kr.metrics.mae(real.flatten(), predictions.flatten())\r\n",
        "mse = kr.metrics.mse(real.flatten(), predictions.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgXtLPDvZEFn"
      },
      "source": [
        "#Model plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZLVI4OkYlTY"
      },
      "source": [
        "size = 200\r\n",
        "\r\n",
        "print(\"\\n\\n######################## Results denormalized ##########################################\")\r\n",
        "print(f'test mae: {np.mean(mae)}')\r\n",
        "print(f'test mse: {np.mean(mse)}')\r\n",
        "print('\\n\\n')\r\n",
        "\r\n",
        "plt.figure(figsize=(8, 4))\r\n",
        "plt.plot(range(len(real[-size:, ...])), real[-size:, ...], label='Real values',linewidth=1)\r\n",
        "plt.plot(range(predictions[-size:, ...].size), predictions[-size:, ...].flatten(), label='Predicted',linewidth=2, linestyle='dashed')\r\n",
        "plt.rc('xtick', labelsize=12) \r\n",
        "plt.rc('ytick', labelsize=12) \r\n",
        "\r\n",
        "plt.gca().spines['top'].set_visible(False)\r\n",
        "plt.gca().spines['right'].set_visible(False)\r\n",
        "plt.suptitle(str(lag) + ' hours prediction Vancouver, MAE: ' + str(round(np.mean(mae),4)), fontsize=18)\r\n",
        "plt.xlabel('time (h)', fontsize=16)\r\n",
        "if feature == 4: \r\n",
        "  plt.ylabel('Temperature (K)', fontsize=16)\r\n",
        "elif feature == 7: \r\n",
        "  plt.ylabel('Wind speed (m/s)', fontsize=16)\r\n",
        "else:\r\n",
        "  plt.ylabel('No label')\r\n",
        "plt.legend(loc=1, prop={'size': 16})\r\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}